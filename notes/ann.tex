\section{Classification with stochastic gradient descent}
\only<presentation>{
  \begin{frame}
    \tableofcontents[ 
    currentsection, 
    hideothersubsections, 
    sectionstyle=show/shaded
    ] 
  \end{frame}
}

\begin{frame}
  \frametitle{Classification as an optimisation problem.}
  \only<article>{Finding the optimal policy for our belief $\bel$ is not normally very difficult. However, it requires that we maintain the complete distribution $\bel$ and that we also under some probability distribution $P$. In simple decision problems, e.g. where the set of actions $\CA$ is finite, it is possible to do this calculation on-the-fly. However, in some cases we might not have a model.
    
Recall that we wish to maximise expected utility for some policy under some distribution. In general, this has the form 
\[
\max_\pol \E^\pol_\model(U).
\]
We also know that any expectation can be approximated by sampling. Let $P_\model(\outcome)$ be the distribution on outcomes defined by our model. Then
\[
\E^\pol_\model(U) = \sum_\omega U(a,\outcome) P_\model(\outcome)
\approx T^{-1} \sum_{t=1}^T U(a,\outcome_t), \qquad \outcome_t \sim P_\model(\outcome),
\]
i.e. when we can replace the explicit summation over all possible outcomes, weighed by their probability through averaging over $T$ outcomes sampled from the correct distribution. In fact this approximation is \alert{unbiased}, as its expectation is equal to the expected utility.
}

  \begin{block}{The $\model$-optimal classifier}
    \only<article>{Since the performance measure is simply an expectation, it is intuitive to directly optimise the decision rule with respect to an approximation of the expectation}
    \begin{align}
      \max_{\alert{\param} \in \Param} &f(\pol_{\alert{\param}}, \model, \util),
      &f(\pol_{\alert{\param}}, \model, \util) &\defn \E^{\pol_{\alert{\param}}}_\model(\util)\\
      f(\pol_{\alert{\param}}, \model, \util) &= 
      \sum_{x, y, a} \util(a, y) \pol_{\alert{\param}}(a \mid x) P_\model(y \mid x) P_\model(x)\\
      &\approx
        \sum_{t=1}^T \sum_{a_t} \util(a_t, y_t) \pol_{\alert{\param```232}}(a_t \mid x_t ),
        & (x_t, y_t)_{t=1}^T &\sim P_\model.
    \end{align}
    \only<article>{In practice, this is the empirical expectation on the training set $\cset{(x_t, y_t)}{t=1, \ldots, T}$. However, when the amount of data is insufficient, this expectation may be far from reality, and so our classification rule might be far from optimal.}
  \end{block}



  \only<article>{
  \begin{block}{The Bayes-optimal classifier}
An alternative idea is to use our uncertainty to create a distribution over models, and then use this distribution to obtain a single classifier that does take the uncertainty into account.
    \[
      \max_\Param f(\pol_\Param, \bel)
      \approx
      \max_\Param N^{-1} \sum_{n=1}^N
      \pol(a_t = y_n \mid x_t = x_n),
      \qquad
      (x_n, y_n) \sim P_{\model_n}, \model_n \sim \bel.
    \]
    In this case, the integrals are replaced by sampling models $\model_n$ from the belief, and then sampling $(x_n, y_n)$ pairs from $P_{\model_n}$.
  \end{block}
  }
\end{frame}

\only<presentation>{
 \againframe{beta-example}
}

\begin{frame}
  \frametitle{Stochastic gradient methdos}
  \only<article>{To find the maximum of a differentiable function $g$, we can use gradient descent}
  \begin{block}{Gradient ascent}
    \[
      \param_{i+1} = \param_i + \alpha \nabla_\param g(\param_i).
    \]
  \end{block}

  \only<article>{When $f$ is an expectation, we don't need to calculate the full gradient. In fact, we only need to take one sample from the related distribution.}
  \begin{block}{Stochastic gradient ascent}
    \[
      g(\param) = \int_\Model f(\param, \model) \dd \bel(\model)
    \]
    \[
      \param_{i+1} = \param_i + \alpha \nabla_\param f(\param_i, \model_i), \qquad \model_i \sim \bel.
    \]
  \end{block}
  \only<article>{Stochastic gradient methods are commonly employed in neural networks.} 
  
\end{frame}


\subsection{Neural network models}
\begin{frame}
  \frametitle{Two views of neural networks}
  \only<article>{In the simplest sense a neural network is simply as parametrised functions $f_\param$. In classification, neural networks can be used as  probabilistic models, so they describes the probability $P_\param(y | \bx)$, or as classification policies so that $f_\param(x, a)$ describes the probability $\pol_\param(a \mid x)$ of selecting class label $a$. Let us begin by describing the simplest type of neural network model, the perceptron.}
  
  \begin{block}{Neural network classification model $P_\param(\by \mid \bx_t)$}
    \begin{tikzpicture}
      \node[RV] at (0,0) (input) {$\bx_t$};
      \node[RV] at (4,0) (output) {$\by_t$};
      \draw[->, bend right] (input) to (output);
    \end{tikzpicture}    
    Objective: Find the best model for $\Training$.
  \end{block}

  
  \begin{block}{Neural network classification policy $\pol(a_t \mid \bx_t)$}
    \begin{tikzpicture}
      \node[RV] at (0,0) (input) {$\bx_t$};
      \node[RV] at (4,0) (output) {$a_t$};
      \draw[->, bend right] (input) to (output);
    \end{tikzpicture}    
    \vspace{1em}
    Objective: Find the best policy for $\util(a, \bx)$.
  \end{block}

  \uncover<2->{
    \begin{alertblock}{Difference between the two views}
      \begin{itemize}
      \item We can use standard probabilistic methods for $P$.
      \item Finding the optimal $\pol$ is an optimisation problem. \only<article>{However, estimating $P$ can also be formulated as an optimisation.}
      \end{itemize}
    \end{alertblock}
  }
\end{frame}


\begin{frame}
  \frametitle{Linear networks and the perceptron algorithm}
  \only<1,2>{
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \node[RV] at (0,0) (input) {$\bx$};
      \node[RV] at (4,0) (output) {$\ba$};
      \draw[->, bend right, label=above:$P$] (input) to (output);
      \uncover<2>{
      \node[RV, hidden] at (2,0) (param) {$\vparam$};
      \draw[->] (param) to (output);
      }
    \end{tikzpicture}
    \caption{Abstract graphical model for a neural network}
    \label{fig:gm-ann}
  \end{figure}
  }
  \only<article>{A neural network as used for modelling classification or regression problems, is simply a parametrised mapping $\CX \to \CY$. If we include the network parameters, then it is instead a mapping $\CX \times \Param \to \CY$, as seen in Figure~\ref{fig:gm-ann}.}
  \only<3,4>{
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \node[RV] at (0,-1) (input1) {$x_1$};
      \node[RV] at (0,1) (input2) {$x_2$};
      \node[RV] at (4,-1) (output1) {$a_1$};
      \node[RV] at (4,1) (output2) {$a_2$};
      \draw[->] (input1) to (output1);
      \draw[->] (input1) to (output2);
      \draw[->] (input2) to (output1);
      \draw[->] (input2) to (output2);
      \uncover<4>{
        \node[RV, hidden] at (2,-1.5) (param11) {$\param_{11}$};
        \node[RV, hidden] at (2,-0.5) (param12) {$\param_{12}$};
        \node[RV, hidden] at (2,0.5) (param21) {$\param_{211}$};
        \node[RV, hidden] at (2,1.5) (param22) {$\param_{22}$};
        \draw[->] (param22) to (output2);
        \draw[->] (param21) to (output2);
        \draw[->] (param12) to (output1);
        \draw[->] (param11) to (output1);
      }
      \draw[-, dashed] (input1) to (input2);
      \draw[-] (output1) to (output2);
    \end{tikzpicture}
    \caption{Graphical model for a linear neural network.}
    \label{fig:gm-ann}
  \end{figure}  
  \only<article>{If we see each possible output as a different random variable, this creates a dependence. After all, we are really splitting one variable into many. In particular, if the network's output is the probability of each action, then we must make sure these sum to 1.}
  }
  \only<5>{
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \node[RV] at (0,-1) (input1) {$x_1$};
      \node[RV] at (0,1) (input2) {$x_2$};
      \node[RV,label={$h_1(\bz) = e^{z_1} / [e^{z_1} + e^{z_2}]$}] at (8,-1) (output1) {$a_1$};
      \node[RV,label={$h_2(\bz) = e^{z_2} / [e^{z_1} + e^{z_2}]$}] at (8,1) (output2) {$a_2$};
      \node[RV,label={$g_{\vparam_1}(\bx) = \bx^\top \vparam_1$}] at (4,-1) (z1) {$z_1$};
      \node[RV,label={$g_{\vparam_2}(\bx) = \bx^\top \vparam_2$}] at (4,1) (z2) {$z_2$};
      \draw[->] (input1) to node[near end, below]{$\param_{11}$} (z1);
      \draw[->] (input1) to node[near end, below]{$\param_{12}$} (z2);
      \draw[->] (input2) to node[near end, above]{$\param_{21}$} (z1);
      \draw[->] (input2) to node[near end, above]{$\param_{22}$} (z2);      
      \draw[->] (z1) to (output1);
      \draw[->] (z1) to (output2);
      \draw[->] (z2) to (output1);
      \draw[->] (z2) to (output2);
    \end{tikzpicture}
    \caption{Architectural view of a linear neural network.}
    \label{fig:gm-ann}
  \end{figure}  
  }



  \begin{definition}[Linear classifier]
    \only<article>{
    A linear classifier with $\nobservations$ inputs and $\nclasses$ outputs is parametrised by}
    \[
    \mparam = 
    \begin{bmatrix}
      \vparam_{1} & \cdots & \vparam_{\nclasses}
    \end{bmatrix}
    =
    \begin{bmatrix}
      \param_{1,1} & \cdots & \param_{1,\nclasses}\\
      \vdots & \ddots & \vdots \\
      \param_{\nobservations} & \cdots & \param_{\nobservations,\nclasses}
    \end{bmatrix}
    \]
    \[
      \pol_\Param(a \mid \bx) = \exp\left(\vparam_a^\top \bx\right) / \sum_{a'} \exp\left(\vparam_{a'}^\top \bx\right) 
    \]
  \end{definition}
  \only<article>{Even though the classifier has a linear structure, the final non-linearity at the end is there to ensure that it defines a proper probability distribution over decisions.}
\only<article>{
  For classification problems, the observations $\bx_{t}$ are features $\bx_t = (x_{t,1} \ldots, x_{t,n})$ so that $\CX \subset \Reals^\nobservations$. 
It is convenient to consider the network output as a vector on the simplex $\by \in \Simplex^\nactions$, i.e. $\sum_{i=1}^\nclasses y_{t,i}  = 1$, $y_{t,i} \geq 0$. In the neural network model for classification, we typically ignore dependencies between the $x_{t,i}$ features, as we are not very interested in the distribution of $\bx$ itself.}

\end{frame}

\begin{frame}
\frametitle{Gradient ascent for a matrix $U$}
\begin{align}
  &\max_\param \sum_{t=1}^T \sum_{a_t} \util(a_t, y_t) \pol_\param(a_t \mid x_t ) \tag{objective}\\
  &\nabla_\param \sum_{t=1}^T \sum_{a_t} \util(a_t, y_t) \pol_\param(a_t \mid x_t ) \tag{gradient}\\
  =& \sum_{t=1}^T \sum_{a_t} \util(a_t, y_t) \nabla_\param \pol_\param(a_t \mid x_t )
\end{align}
\only<article>{We now need to calculate the gradient of the policy.}
\begin{block}{Chain Rule of Differentiation}
  \begin{align*}
    f(z), z = g(x), && \frac{df}{dx} &= \frac{df}{dg} \frac{dg}{dx} \tag{scalar version}\\
    && \nabla_\param \pol &= \nabla_g \pol \nabla_\param g \tag{vector version}
  \end{align*}
\end{block}
\end{frame}


\begin{frame}
  \frametitle{Learning outcomes}
  \begin{block}{Understanding}
    \begin{itemize}
    \item Classification as an optimisation problem.
    \item (Stochastic) gradient methods and the chain rule.
    \item Neural networks as probability models or classification policies.
    \item Linear neural netwoks.
    \item Nonlinear network architectures.
    \end{itemize}
  \end{block}
  
  \begin{block}{Skills}
    \begin{itemize}
    \item Using a standard NN class in python.
    \end{itemize}
  \end{block}

  \begin{block}{Reflection}
    \begin{itemize}
    \item How useful is the ability to have multiple non-linear layers in a neural network.
    \item How rich is the representational power of neural networks?
    \item Is there anything special about neural networks other than their allusions to biology?
    \end{itemize}
  \end{block}
  
\end{frame}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "notes"
%%% End:

